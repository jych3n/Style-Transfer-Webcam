{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPL3z-gDHuQ"
      },
      "source": [
        "# Train and Style Transfer model and run it in ml5.js/tf.js"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcY9cMXsDL8b"
      },
      "source": [
        "## 1. Preparing your environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dkk2v3JCuEW",
        "outputId": "98973e25-2ec3-4734-f461-8dc1a5f6f9f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fast-style-transfer'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 248 (delta 2), reused 5 (delta 0), pack-reused 238\u001b[K\n",
            "Receiving objects: 100% (248/248), 11.02 MiB | 11.46 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the fast-style-transfer git repo from github: https://github.com/lengstrom/fast-style-transfer.\n",
        "!git clone https://github.com/lengstrom/fast-style-transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4qwxD7ZEMgD"
      },
      "source": [
        "### Add a style image\n",
        "1. Go to left sidebar, click on the folder icon to open \"Files\" panel\n",
        "2. Create a folder called 'ckpt' inside of 'fast-style-transfer' folder\n",
        "3. Create another folder called 'images' inside of 'fast-style-transfer' folder\n",
        "4. Inside of the 'images' folder, create a folder called 'style'\n",
        "5. Put a style image inside of the 'style' folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF1kfOS9dJHF"
      },
      "source": [
        "### Install some libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jii5lBIVY1cs",
        "outputId": "a1352455-0d60-4146-de6a-bf5ebd1a5895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==2.1.0\n",
            "  Downloading tensorflow_gpu-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 5.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (0.37.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.44.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.14.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.1.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=596015016f6f412f26c7d9fdc92f05ec423664a2dfd76174bef63f10a28da2c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "tensorflow 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.1.1 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install tensorflow\n",
        "!pip install tensorflow-gpu==2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEctG-61ZIF6",
        "outputId": "665c5f34-1146-4210-f570-bfe0d5b37ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.64.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# Install other libraries\n",
        "!apt install ffmpeg\n",
        "!pip install moviepy\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-DB6canDn5B",
        "outputId": "f5f8c492-4e96-47d0-e709-aa0c68f02cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fast-style-transfer\n"
          ]
        }
      ],
      "source": [
        "# go to fast-style-transfer \n",
        "%cd fast-style-transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0cGgkydQV6n",
        "outputId": "becf40aa-75c9-49c5-a044-fb1bb4b24004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CITATION.cff  docs.md      \u001b[0m\u001b[01;34mexamples\u001b[0m/  README.md  \u001b[01;34msrc\u001b[0m/      transform_video.py\n",
            "\u001b[01;34mckpt\u001b[0m/         evaluate.py  \u001b[01;34mimages\u001b[0m/    \u001b[01;32msetup.sh\u001b[0m*  style.py\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSC4tPjEImCI"
      },
      "source": [
        "# 2. Downloading Datasets\n",
        "\n",
        "The following step is downloading dataset, it may take 1 hour to finish. Keep this web tab active, and don't close it, wait util the following cell stopped loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8shkSNWddtvm",
        "outputId": "780c213c-4e7d-4ac5-bb2d-295886349f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-23 22:56:56--  http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Resolving www.vlfeat.org (www.vlfeat.org)... 64.90.48.57\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat [following]\n",
            "--2022-04-23 22:56:57--  https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576042600 (549M)\n",
            "Saving to: ‘imagenet-vgg-verydeep-19.mat’\n",
            "\n",
            "imagenet-vgg-veryde 100%[===================>] 549.36M  18.0MB/s    in 32s     \n",
            "\n",
            "2022-04-23 22:57:29 (17.3 MB/s) - ‘imagenet-vgg-verydeep-19.mat’ saved [576042600/576042600]\n",
            "\n",
            "--2022-04-23 22:57:29--  http://msvocds.blob.core.windows.net/coco2014/train2014.zip\n",
            "Resolving msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)... 20.60.195.163\n",
            "Connecting to msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)|20.60.195.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/octet-stream]\n",
            "Saving to: ‘train2014.zip’\n",
            "\n",
            "train2014.zip       100%[===================>]  12.58G  9.97MB/s    in 35m 50s \n",
            "\n",
            "2022-04-23 23:33:20 (5.99 MB/s) - ‘train2014.zip’ saved [13510573713/13510573713]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!./setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwj2HgUlIrtH"
      },
      "source": [
        "# 3. Training with style.py\n",
        "Keep this cell running, keep the tab active and wait. It took me 2 hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypI9UexsKiiN",
        "outputId": "f611ab47-0d11-4e35-ab2a-e271c649d7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-23 23:51:11.332185: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-04-23 23:51:11.332823: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-04-23 23:51:11.332860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Train set has been trimmed slightly..\n",
            "(1, 1200, 817, 3)\n",
            "2022-04-23 23:51:15.310343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-23 23:51:15.380168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:15.380787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-04-23 23:51:15.394360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-23 23:51:15.588690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-23 23:51:15.630003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-23 23:51:15.726737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-23 23:51:16.077443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-23 23:51:16.094511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-23 23:51:16.444921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-23 23:51:16.445118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:16.445833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:16.446365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2022-04-23 23:51:16.447029: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-04-23 23:51:16.455800: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-04-23 23:51:16.456106: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a009de7100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-23 23:51:16.456137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-04-23 23:51:16.726198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:16.727011: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a009de6f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-23 23:51:16.727041: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-04-23 23:51:16.727205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:16.727780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-04-23 23:51:16.727844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-23 23:51:16.727867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-23 23:51:16.727888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-23 23:51:16.727914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-23 23:51:16.727937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-23 23:51:16.727956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-23 23:51:16.727974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-23 23:51:16.728044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:16.728625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:16.729127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2022-04-23 23:51:16.732562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-23 23:51:16.733819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-23 23:51:16.733849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2022-04-23 23:51:16.733860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2022-04-23 23:51:16.737486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:16.738073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:16.738620: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-04-23 23:51:16.738663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2022-04-23 23:51:19.896363: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 250982400 exceeds 10% of system memory.\n",
            "2022-04-23 23:51:20.304150: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 250982400 exceeds 10% of system memory.\n",
            "2022-04-23 23:51:20.577647: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 250982400 exceeds 10% of system memory.\n",
            "tcmalloc: large alloc 2259066880 bytes == 0x55a0553ec000 @  0x7f21bc9bf1e7 0x7f217360dc55 0x7f2173626115 0x7f21783deafa 0x7f21789bd132 0x7f21789be1c1 0x7f2178a8b34e 0x7f2178a8eefd 0x7f2178a8f3ef 0x7f216f41259c 0x7f216f404b85 0x7f216f4f35d1 0x7f216f4f02e3 0x7f21bb2a16df 0x7f21bc7746db 0x7f21bb8a961f\n",
            "2022-04-23 23:51:21.722290: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 62822400 exceeds 10% of system memory.\n",
            "2022-04-23 23:51:21.790561: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 125644800 exceeds 10% of system memory.\n",
            "tcmalloc: large alloc 2259066880 bytes == 0x55a046490000 @  0x7f21bc9bf1e7 0x7f217360dc55 0x7f2173626115 0x7f21783deafa 0x7f21789bd132 0x7f21789be1c1 0x7f2178a8b34e 0x7f2178a8eefd 0x7f2178a8f3ef 0x7f216f41259c 0x7f216f4129df 0x7f216f4f35d1 0x7f216f4f02e3 0x7f21bb2a16df 0x7f21bc7746db 0x7f21bb8a961f\n",
            "tcmalloc: large alloc 2259066880 bytes == 0x55a046490000 @  0x7f21bc9bf1e7 0x7f217360dc55 0x7f2173626115 0x7f21783deafa 0x7f21789bd132 0x7f21789be1c1 0x7f2178a8b34e 0x7f2178a8eefd 0x7f2178a8f3ef 0x7f216f41259c 0x7f216f404b85 0x7f216f4f35d1 0x7f216f4f02e3 0x7f21bb2a16df 0x7f21bc7746db 0x7f21bb8a961f\n",
            "tcmalloc: large alloc 2259066880 bytes == 0x55a046490000 @  0x7f21bc9bf1e7 0x7f217360dc55 0x7f2173626115 0x7f21783deafa 0x7f21789bd132 0x7f21789be1c1 0x7f2178a8b34e 0x7f2178a8eefd 0x7f2178a8f3ef 0x7f216f41259c 0x7f216f404b85 0x7f216f4f35d1 0x7f216f4f02e3 0x7f21bb2a16df 0x7f21bc7746db 0x7f21bb8a961f\n",
            "2022-04-23 23:51:41.799240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:41.800087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-04-23 23:51:41.800181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-23 23:51:41.800204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-23 23:51:41.800226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-23 23:51:41.800245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-23 23:51:41.800264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-23 23:51:41.800285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-23 23:51:41.800308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-23 23:51:41.800417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:41.801193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:41.801944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2022-04-23 23:51:41.801995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-23 23:51:41.802010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2022-04-23 23:51:41.802021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2022-04-23 23:51:41.802165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:41.804048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-23 23:51:41.804803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "UID: 30\n",
            "2022-04-23 23:51:51.504331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-23 23:51:54.455604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "Epoch 0, Iteration: 2000, Loss: 14093290.0\n",
            "style: 6074399.5, content:7287247.5, tv: 731643.06\n",
            "Epoch 0, Iteration: 4000, Loss: 11931371.0\n",
            "style: 4864260.0, content:6741998.5, tv: 325112.84\n",
            "Epoch 0, Iteration: 6000, Loss: 11657078.0\n",
            "style: 4402518.5, content:7001794.0, tv: 252765.77\n",
            "Epoch 0, Iteration: 8000, Loss: 11264013.0\n",
            "style: 3898048.5, content:7139005.5, tv: 226959.39\n",
            "Epoch 0, Iteration: 10000, Loss: 10062340.0\n",
            "style: 3421790.0, content:6432327.5, tv: 208221.83\n",
            "Epoch 0, Iteration: 12000, Loss: 9942817.0\n",
            "style: 3185340.0, content:6555663.0, tv: 201813.78\n",
            "Epoch 0, Iteration: 14000, Loss: 9232961.0\n",
            "style: 3003153.2, content:6040527.0, tv: 189281.31\n",
            "Epoch 0, Iteration: 16000, Loss: 9508858.0\n",
            "style: 2955144.5, content:6366660.0, tv: 187053.77\n",
            "Epoch 0, Iteration: 18000, Loss: 9767166.0\n",
            "style: 2865565.8, content:6716012.0, tv: 185587.92\n",
            "Epoch 0, Iteration: 20000, Loss: 9491929.0\n",
            "style: 3580906.0, content:5730644.0, tv: 180379.34\n",
            "Epoch 1, Iteration: 2000, Loss: 8743235.0\n",
            "style: 2600402.2, content:5960349.5, tv: 182482.75\n",
            "Epoch 1, Iteration: 4000, Loss: 8811279.0\n",
            "style: 2992846.0, content:5645909.0, tv: 172523.58\n",
            "Epoch 1, Iteration: 6000, Loss: 8738415.0\n",
            "style: 2794991.5, content:5769026.0, tv: 174396.64\n",
            "Epoch 1, Iteration: 8000, Loss: 8948690.0\n",
            "style: 2665697.5, content:6107521.0, tv: 175472.06\n",
            "Epoch 1, Iteration: 10000, Loss: 8492238.0\n",
            "style: 2544578.2, content:5772167.0, tv: 175493.1\n",
            "Epoch 1, Iteration: 12000, Loss: 8665765.0\n",
            "style: 2749234.0, content:5750958.5, tv: 165573.1\n",
            "Epoch 1, Iteration: 14000, Loss: 8069599.5\n",
            "style: 2495017.0, content:5402598.5, tv: 171984.16\n",
            "Epoch 1, Iteration: 16000, Loss: 8617378.0\n",
            "style: 2631113.0, content:5819528.0, tv: 166736.88\n",
            "Epoch 1, Iteration: 18000, Loss: 8743275.0\n",
            "style: 2495578.5, content:6079796.5, tv: 167899.64\n",
            "Epoch 1, Iteration: 20000, Loss: 8525552.0\n",
            "style: 3013487.0, content:5343014.0, tv: 169050.89\n",
            "Epoch 1, Iteration: 20695, Loss: 8108282.5\n",
            "style: 2530503.2, content:5408799.0, tv: 168980.56\n",
            "Training complete. For evaluation:\n",
            "    `python evaluate.py --checkpoint ckpt ...`\n"
          ]
        }
      ],
      "source": [
        "# Remember to replace the name after 'images/style/' to your own style image name\n",
        "# You can change the number after --epoch to change the training time, default to 2, it has to be > 0\n",
        "!python style.py --checkpoint-dir ckpt --style images/style/fujichoko.png --style-weight 1.5e2 --train-path data/train2014 --vgg-path data/imagenet-vgg-verydeep-19.mat --epochs 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQX2AeuXd-LB"
      },
      "source": [
        "At this point, you will be able to see 4 files in the '/fast-style-transfer/ckpt' folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziBLDaHSIr_2"
      },
      "source": [
        "# 4. Converting model to ml5js"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "903jSW-5WlAr",
        "outputId": "d2ae459a-f3fa-4e90-8ae6-074062f0e020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 56 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.44.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-gpu 2.1.0 requires tensorboard<2.2.0,>=2.1.0, but you have tensorboard 1.14.0 which is incompatible.\n",
            "tensorflow-gpu 2.1.0 requires tensorflow-estimator<2.2.0,>=2.1.0rc0, but you have tensorflow-estimator 1.14.0 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow==1.14.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW2jDqCOX7Un",
        "outputId": "6998e177-687f-4f9a-8323-204a3352eebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'fast-style-transfer-deeplearnjs'...\n",
            "remote: Enumerating objects: 1407, done.\u001b[K\n",
            "remote: Total 1407 (delta 0), reused 0 (delta 0), pack-reused 1407\u001b[K\n",
            "Receiving objects: 100% (1407/1407), 37.97 MiB | 16.77 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n",
            "/content/fast-style-transfer-deeplearnjs\n"
          ]
        }
      ],
      "source": [
        "%cd ../\n",
        "!git clone https://github.com/reiinakano/fast-style-transfer-deeplearnjs.git\n",
        "%cd fast-style-transfer-deeplearnjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6ky6qQhYJBz",
        "outputId": "faae7a95-5ebb-4d0c-fedb-f74a1826120c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From scripts/dump_checkpoint_vars.py:48: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "WARNING:tensorflow:From scripts/dump_checkpoint_vars.py:51: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "Writing variable beta2_power...\n",
            "Writing variable beta1_power...\n",
            "Writing variable Variable_9/Adam_1...\n",
            "Writing variable Variable_9/Adam...\n",
            "Writing variable Variable_8/Adam_1...\n",
            "Writing variable Variable_8...\n",
            "Writing variable Variable_7/Adam_1...\n",
            "Writing variable Variable_7/Adam...\n",
            "Writing variable Variable_7...\n",
            "Writing variable Variable_6/Adam_1...\n",
            "Writing variable Variable_6/Adam...\n",
            "Writing variable Variable_47/Adam...\n",
            "Writing variable Variable_46...\n",
            "Writing variable Variable_45/Adam...\n",
            "Writing variable Variable_45...\n",
            "Writing variable Variable_44...\n",
            "Writing variable Variable_43/Adam_1...\n",
            "Writing variable Variable_43/Adam...\n",
            "Writing variable Variable_43...\n",
            "Writing variable Variable_42...\n",
            "Writing variable Variable_41/Adam_1...\n",
            "Writing variable Variable_44/Adam_1...\n",
            "Writing variable Variable_41/Adam...\n",
            "Writing variable Variable_41...\n",
            "Writing variable Variable_40/Adam...\n",
            "Writing variable Variable_4...\n",
            "Writing variable Variable_6...\n",
            "Writing variable Variable_39/Adam_1...\n",
            "Writing variable Variable_39/Adam...\n",
            "Writing variable Variable_39...\n",
            "Writing variable Variable_38/Adam_1...\n",
            "Writing variable Variable_38/Adam...\n",
            "Writing variable Variable_44/Adam...\n",
            "Writing variable Variable_38...\n",
            "Writing variable Variable_37/Adam...\n",
            "Writing variable Variable_37...\n",
            "Writing variable Variable_36...\n",
            "Writing variable Variable_35...\n",
            "Writing variable Variable_34/Adam...\n",
            "Writing variable Variable_35/Adam_1...\n",
            "Writing variable Variable_34/Adam_1...\n",
            "Writing variable Variable_34...\n",
            "Writing variable Variable_33/Adam_1...\n",
            "Writing variable Variable_33/Adam...\n",
            "Writing variable Variable_33...\n",
            "Writing variable Variable_32/Adam_1...\n",
            "Writing variable Variable_32/Adam...\n",
            "Writing variable Variable_42/Adam_1...\n",
            "Writing variable Variable_32...\n",
            "Writing variable Variable_45/Adam_1...\n",
            "Writing variable Variable_19/Adam_1...\n",
            "Writing variable Variable_17/Adam_1...\n",
            "Writing variable Variable_40/Adam_1...\n",
            "Writing variable Variable_30/Adam_1...\n",
            "Writing variable Variable_40...\n",
            "Writing variable Variable_31...\n",
            "Writing variable Variable_18...\n",
            "Writing variable Variable_26/Adam_1...\n",
            "Writing variable Variable_35/Adam...\n",
            "Writing variable Variable_31/Adam...\n",
            "Writing variable Variable_16/Adam_1...\n",
            "Writing variable Variable_47/Adam_1...\n",
            "Writing variable Variable_47...\n",
            "Writing variable Variable_19/Adam...\n",
            "Writing variable Variable_15/Adam_1...\n",
            "Writing variable Variable_8/Adam...\n",
            "Writing variable Variable_24/Adam...\n",
            "Writing variable Variable_14/Adam_1...\n",
            "Writing variable Variable_13/Adam_1...\n",
            "Writing variable Variable_12/Adam_1...\n",
            "Writing variable Variable_4/Adam_1...\n",
            "Writing variable Variable_22/Adam...\n",
            "Writing variable Variable_13...\n",
            "Writing variable Variable/Adam_1...\n",
            "Writing variable Variable...\n",
            "Writing variable Variable_11/Adam_1...\n",
            "Writing variable Variable_17...\n",
            "Writing variable Variable_18/Adam...\n",
            "Writing variable Variable_16...\n",
            "Writing variable Variable_20...\n",
            "Writing variable Variable_13/Adam...\n",
            "Writing variable Variable_1...\n",
            "Writing variable Variable_2/Adam...\n",
            "Writing variable Variable_4/Adam...\n",
            "Writing variable Variable_27/Adam_1...\n",
            "Writing variable Variable_5/Adam...\n",
            "Writing variable Variable_3/Adam...\n",
            "Writing variable Variable_1/Adam_1...\n",
            "Writing variable Variable_37/Adam_1...\n",
            "Writing variable Variable_10/Adam_1...\n",
            "Writing variable Variable_29/Adam_1...\n",
            "Writing variable Variable_1/Adam...\n",
            "Writing variable Variable_26...\n",
            "Writing variable Variable_46/Adam...\n",
            "Writing variable Variable_10/Adam...\n",
            "Writing variable Variable_16/Adam...\n",
            "Writing variable Variable_12...\n",
            "Writing variable Variable_36/Adam_1...\n",
            "Writing variable Variable_3...\n",
            "Writing variable Variable_15/Adam...\n",
            "Writing variable Variable_11/Adam...\n",
            "Writing variable Variable_28/Adam...\n",
            "Writing variable Variable_15...\n",
            "Writing variable Variable_11...\n",
            "Writing variable Variable_9...\n",
            "Writing variable Variable_20/Adam...\n",
            "Writing variable Variable_12/Adam...\n",
            "Writing variable Variable_29...\n",
            "Writing variable Variable_2...\n",
            "Writing variable Variable_2/Adam_1...\n",
            "Writing variable Variable_24...\n",
            "Writing variable Variable_24/Adam_1...\n",
            "Writing variable Variable_20/Adam_1...\n",
            "Writing variable Variable_21...\n",
            "Writing variable Variable_14...\n",
            "Writing variable Variable_21/Adam...\n",
            "Writing variable Variable_17/Adam...\n",
            "Writing variable Variable_21/Adam_1...\n",
            "Writing variable Variable_22...\n",
            "Writing variable Variable_5/Adam_1...\n",
            "Writing variable Variable_22/Adam_1...\n",
            "Writing variable Variable_14/Adam...\n",
            "Writing variable Variable_26/Adam...\n",
            "Writing variable Variable_23/Adam...\n",
            "Writing variable Variable_46/Adam_1...\n",
            "Writing variable Variable_23/Adam_1...\n",
            "Writing variable Variable_42/Adam...\n",
            "Writing variable Variable_36/Adam...\n",
            "Writing variable Variable_25...\n",
            "Writing variable Variable_25/Adam...\n",
            "Writing variable Variable_10...\n",
            "Writing variable Variable_25/Adam_1...\n",
            "Writing variable Variable_27...\n",
            "Writing variable Variable_27/Adam...\n",
            "Writing variable Variable_28...\n",
            "Writing variable Variable_29/Adam...\n",
            "Writing variable Variable_3/Adam_1...\n",
            "Writing variable Variable_18/Adam_1...\n",
            "Writing variable Variable_23...\n",
            "Writing variable Variable_30...\n",
            "Writing variable Variable_5...\n",
            "Writing variable Variable_19...\n",
            "Writing variable Variable_28/Adam_1...\n",
            "Writing variable Variable_30/Adam...\n",
            "Writing variable Variable/Adam...\n",
            "Writing variable Variable_31/Adam_1...\n",
            "Writing manifest to src/ckpts/fujichoco/manifest.json\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Change src/ckpts/picasso to src/ckpts/YOUR_OWN_FOLDER\n",
        "!python scripts/dump_checkpoint_vars.py --output_dir=src/ckpts/fujichoco --checkpoint_file=../fast-style-transfer/ckpt/fns.ckpt\n",
        "# Change src/ckpts/picasso to src/ckpts/YOUR_OWN_FOLDER\n",
        "!python scripts/remove_optimizer_variables.py --output_dir=src/ckpts/fujichoco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCt42jBqY_rA",
        "outputId": "df20c8f1-36b3-4557-af43-4b11ed54f5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/ (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_5 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_47 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_13 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_7 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_38 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_11 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_39 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_15 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_6 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_12 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_43 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_44 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_27 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_22 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_4 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_16 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_45 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_34 (deflated 1%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_29 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/manifest.json (deflated 91%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_3 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_26 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_31 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_36 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_37 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_25 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_23 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_40 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_32 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_8 (deflated 3%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_21 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_35 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_42 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_9 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_2 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_17 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_24 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_41 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_18 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_28 (deflated 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_33 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_1 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_20 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_46 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_14 (deflated 3%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_30 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_10 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco/Variable_19 (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "# Change /piccasso.zip to /YOUR_FOLDER_NAME.zip, same as src/ckpts/picasso to /YOUR_FOLDER_NAME\n",
        "!zip -r /content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco.zip /content/fast-style-transfer-deeplearnjs/src/ckpts/fujichoco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8_X2DJIMiJW"
      },
      "source": [
        "# 5. Run it with ml5js\n",
        "Now, you should be able to see a 'pollock' .zip file at \"fast-style-transfer-deeplearnjs/src/ckpts/pollock.zip\". (Sometimes, you need to refresh the Files panel, right click to refresh)\n",
        "\n",
        "Download the 'pollock' folder and put it into your p5 sketch(https://github.com/yining1023/machine-learning-for-the-web/tree/master/week5-styleTransfer/styleTransfer-ml5/StyleTransfer_Video) under models/.\n",
        "\n",
        "Change the model path in your p5 sketch: style = ml5.styleTransfer('models/pollock', video, modelLoaded);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Train-Fast-style-transfer-tensorflow-ml5js.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}